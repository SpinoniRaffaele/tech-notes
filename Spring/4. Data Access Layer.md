DTO: data transfer object: is an object that maps a representation from a lower level to an higher one. (like a service that maps the DAO to the JSON returned by the controller, in a REST app).

Spring supports many database implementations and can be integrated with many frameworks that enrich data management (Hibernate, MyBatis)
To perform operations over a database a connection is needed, in order to establish the connection we need to provide a **database driver**, a **URL** connection entry point, database **credentials/key**.

The most basic way to interact with a database is to use the vanilla java implementation: JDBC
It requires the developer to write code to open and close the connection, and any object that are build on top of the connection (such as prepared statement and row mappers). You generally end up with code that is hard to maintain and to test.

```
//repository class, findAll method
try {
    Connection conn = dataSource.getConnection();  //data source is a bean configured with the db credentials
    PreparedStatement ps = conn.prepaeStatement("select * from ...");
    ResultSet rs = ps.executeQuery();
    persons = mapPersons(rs);
} catch (SQLException e) {
    //..handle the exception
} finally {
    rs.close();
    ps.close();
    conn.close();  //not releasing those resources causes memory leaks
}

//the code of the mapPersons(rs) method:
Set<Persons> persons = new HashSet<>();
Person person;
while (rs.next()) {
    person = new Person(rs.getLong("ID"), re.getString("USERNAME"), ....);
}
return persons;
```

**JDBC TEMPLATE**
Spring's abstraction over the JDBC implementation. The JDBCTemplate class is designed following the template design pattern, which uses an abstract class to define the skeleton of a method and then uses subclasses to provide the effective implementation which fills the gaps of the template. JdbcTemplate is a Spring specialized class that uses dataSource implementation to create and release resources, support statements creation and execution, it catches and maps SQLExceptions to proper unchecked exceptions of the _org.springframework.dao_ package.

**DATASOURCE: it's a set of properties linking the app to the DB,  and a connection pool which keeps a set open connections to the DB.**

In order to use JDBCTemplate we need the following 5 steps:

1. a file containing SQL DDL(data definition language) scripts for initializing the DB (.sql file initializing tables)
2. a file containing SQL DML(data manipulation language) test data (.sql file inserting rows in the tables)
3. a configuration class that initializes the beans needed for the db connection: dataSource, jdbcTemplate

```
@Configuration
public class TestDBConfig {
    @Bean
    public JdbcTemplate jdbcTemplate() {
        return new JdbcTemplate(dataSource());
    }

    @Bean
    public DataSource dataSource() {
        EmbeddedDatabaseBuilder builder = new EmbeddedDatabaseBuilder();
        EmbeddedDatabase db = builder.setType(EmbeddedDatabaseType.H2)
                .generateUniqueName(true).addScript("db/schema.sql").addScript("db/testData.sql"); 
        //it's eessential that you add the scripts in the correct order
        return db;
    }
}

//an other exaple of the dataSource bean declaration (closer to reality)
public DataSource dataSource() {
    try {
        var dataSource = new SimpleDriverDataSource();  //instantiate other DB driver here is other are used (ex: OracleDataSource())
        dataSoruce.setDriverClass(DriverClass.class);  //this is also database dependant
        dataSource.setUrl(url);
        dataSource.setUsername(username);
        dataSource.setPassword(password);
        return dataSource;
    } catch (Excption e) {
        //excpetion handling...
    }
}
```
Spring (apart from connecting to most of the DBs) supports in memory databases useful to test the code: HSQLDB and Derby.

4. another configuration class to scan for the repositories:

```
@Configuration
@ComponentScan(basePackages = {"com.example.repos"})
public class TestConfig {}
```

5. one repository implementation (at least) with its RowMapper class.

```
@Repository
public class PersonRepo extends JdbcAbstractRepo<Person> {

    private RowMapper<Person> rowMapper = new PersonRowMapper();

    public PersonRepo(JdbcTemplate jdbcTemplate) {
        super(jdbcTemplate);
    }

    @Override
    public Optional<Person> findById(Long id) {
        var sql = "select ID, USERNAME, PASSWORD" from PERSON where ID = ?";
        return Optional.of(jdbcTemplate.queryForObject(sql, rowMapper, id));
    }

    private ClassPersonRowMapper implementns RowMapper<Person> {
        @Override
        public Person mapRow(ResultSet rs, int rowNum) throws SQLException {
            return new Person(rs.getLong("ID"), rs.getString("USERNAME")), rs.getString("PASSWORD"));
        }
    }
}
```
The necessity of writing the code to map sql results to the model will disappear thanks to the usage of ORM (more on this later)

In this example we use the ._queryForObject_ method, in the background it acquires a DB connection, creates a transaction in which execute the statement, it executes the statement, it process the resultSet using the mapper, it maps exceptions, it closes the connection and release the transaction.
TRANSACTION: group of actions that should be performed as they were one single action. the default of JDBC is that each statement is a single transaction (so composing multiple statements in a single transaction is not possible in vanilla JDBC)

As you've seen JdbcTemplate supports the queries with '?' placeholder, but also named parameters.
The method queryForObject should be used when the query returns one row, in the example it needed a rowMapper because of the complex object returned, if the query returns a primitive type you can use:
```
queryForInt(query);
queryForString(query);
//retrun a map of column name -> java object (you will still need to convert the object)
Map<String, Object> map = queryForMap(query, id); //each entry in the map is a column name -> value
//return a list of maps:
List<Map<String, Object>> list = queryForList(sql);
```

The query method, is polymorphic
```
Set<Person> persons = jdbcTemplate.query(sql, rowMapper);

//consider the case of a complex query extracting columns from multiple tables (Detective and Person)
String sql = "select p.ID pid, d.ID did, from DETECTIVE d, PERSON p where d.PERSON_ID = p.ID and d.ID = 1";
Detective d = jdbcTemplate.query(sql, new DetectiveExtractor); 
//the second arguemnt is a @FunctionalInterface that is a callback applied to the results returned by the DB

private class DetectiveExtractor implements ResultSetExtractor<Detective> {
    @Override
    public Detective extractData(ResultSet rs) throws SQLException {
        Detective detective = new Detective();
        while(rs.next()) {
            detective.setId(rs.getLong("did"));
            detective.setPerson(new Person(rs.getLong("pid")));
        }
        return detective;
    }
}
```

You can also  perform INSERT, UPDATE, DELETE operations using the _update_ method (which returns a int representing the number of lines affected).
```
public int createPerson(Long id, String username) {
    return jdbcTemplate.update("insert into PERSON(ID, USERNAME) values(?, ?)", id, username);
}

public int updatePassword(Long id, String password) {
    return jdbcTemplate.update("update PERSON set password=? where ID=?", password, id);
}

//same for delete
```

You can also execute DDL (create tables, views, cursors) using the _execute_ maethod:
```
public void createTable(String name) {
    jdbcTemplate.execute("create table" + name " (id integer, name varchar(20))");
}
```

**NamedParameterJdbcTemplate**
This is a class that uses JdbcTemplate. it provides methods analogous to the ones in the JdbcTemplate with the difference of accepting a map of paramName -> value, so that the query can refer to named parameters instead of multiple '?' that then relies on the order of the parameter passed.
```
public Person bindById(Long entityId) {
    String sql = "select ID, USERNAME from PERSON where ID = :id";
    return jdbcNamedTemplate,queryForObject(sql, Map.of("id", entityId), rowMapper);  //maps entityId to the :id in the query
}
```

**Exceptions**
In JDBC the same SQLException is always thrown, with different error codes, spring wraps it with unchecked exceptions that you don't need to specify in the calls, they are also mapped to different more explicit expection types
They are splitted in three categories:

* NonTransientDataAccessException: it means the retrying the same operation after having received this exception will cause again the same error (findById with the same ID two times, or functional issues in the way we interact with the DB -> developers responsability)
* RecoverableDataAccessException: the next operation might work if some recovery steps are performed (ex: connection to db failer for temporary network issue)
* TransientDataAccesssException: the retry operation might success without any operation in the middle (ex: timeout)

**TRANSACTION**
In order to group more SQL operations together we need a transaction which has the following properties:

* Atomicity: the transaction should execute as a single operation either all or nothing
* Consistency: each transaction should end in a consistent state
* Isolation: each transaction should perform isolated from the others, as if the other transaction were executed sequentially after (even if they are parallel)
* Durability: the result of a transaction should be persisted

In spring transactions are managed by a transaction manager bean, there are different flavors based on the underlying technology used to access and map data from the DB:

* DataSourceTransactionManager: used together with dataSource in the case of plain JDBC connection (also with JdbcTemplate is fine)
* HibernateTransactionManager: used together with hibernate framework which provides ORM (the repositories use a HibernateSession to communicate with the DB)
* JpaTransactionManager: used together with JPA (the repositories use a EntityManager to communicate with the DB)
* JtaTransactionManager: is a setup where an application server provides access to remote dataSorce beans, useful for distributed computing environment

Under the hood, spring uses AOP Proxy to implement the transaction behavior which is a cross-cutting concern:
before a method that needs a transaction is executed, a transaction is retrieved and opened, then at the end it is commited and released (an **Around** advice is used)

In order to make a method transactional you need the @Transactional annotation (and it must be public otherwise the proxy cannot wrap it).
Steps to be taken to add transaction support to a spring application:

1. Configure the transaction manager bean:

```
@Configuration
public class Config {
    @Bean
    public PlatformTransactionManager platformTransactionManager() {
        return new DataSourceTransactionManager
    }
}
```

2. activate transaction management by annotating the configuration class with: **@EnableTransactionManagment**
3. declare some transactional methods using the @Transactional annotation (generally it is done in the service layer)

If you have the need of using multiple transaction managers, in order to tell spring which one to use when enabling the transaction management you have to modify the config
it has to extend the **TransactionManagementConfigurer** and override his method **annotationDrivenTransactionManager**:
```
@Configuration
@EnableTransactionManagement
public class Config extends TransactionManagementConfigurer {
    @Bean
    PlatformTransactionManager txManager1() { ... }

    @Bean
    PlatformTransactionManager txManager2() { ... }

    @Override
    public TransactionManager annotationDrivenTransactionManager() {
        return txManager1();  //tell spring to use the first of the two tx managers when setting up the transaction management
    }
}
```
In the same case of multiple transaction managers, you can specify which one to use in each method using the @Transactional annotation:
```
@Transactional(transactionMnaager = "txMnager1")
```
even another option is to annotate one of the two beans in the config with **@Primary** which tells that is the one to be chosen when in doubt.

More attributes of the transactional annotation:

* **readOnly**: is set to true for operations that do not write in the DB (false by default)
* **propagation**: uses the Propagation enum to define the behaivor
	* **REQUIRED** \-> a free transaction is used, if it's not present  a new one will be created (default)
	* **REQUIRES\_NEW** a new transaction is created (in this case if a transaction calls another method with transaction in another object, a second transactional context will be crated)
	* NESTED: same as required but uses nested transactions if they are supported by the DB (nested transaction: transaction in another transaction, you can create this by annotating with transactional both the main method and the method called inside it - which is a method called on a different object w.r.t to the previous method, the one inside must specify the NESTED propagation)
	* MANDATORY: only an existing transaction can be used to execute, if no transaction is available an exception is thrown.
	* NEVER: only executes on new transaction, if a transaction exists -> exception
	* SUPPORTS: uses a transaction if available,  but it executes outside a transaction is none is available.
* **isolation**: it determines how data modified in a transaction affects other transactions, values (in order of growing isolation):
	* DEFAULT: the default level of the DBMS
	* READ\_UNCOMMITED: data that is changing in a transaction can be read by another transaction even if the first one has not commit yet (**dirty reads**)
	* READ\_COMMITED: it prevents dirty reads ensuring that the last value is always retrieved. It still suffers from **non-repeatable read** (a second read on the same data within the same transaction could lead to a different result, because in the meantime another transaction has updated the value being read).
	* REPEATABLE\_READ : it prevents dirty reads and also non-repeatable reads, but it suffers from **phantom reads**: in the course of a single transaction, the execution of identical queries leads to different results set, ex: new data added) (done with a lock in the row)
	* SERIALIZABLE: Transaction are really executed in a transactional level (done in practice with a table lock)
* **timeout**: the milliseconds after which a transaction is considered failed.
* **rollbackFor**: specifies an Exception class for which the transaction rolls back if it occurs
* **noRollbackFor**: specified an Exception class for which the transaction should not rollback (by default a transaction rolls back for RuntimeExceptions)

transactional can also be used at class level, causing all the public methods to inherit it, then each method can have a different transactional annotation to override the one defined at class level.
It is practical and recommended to annotate only concrete method and classes with transactional.

**TEST TRANSACTIONAL**
You can use the transactional annotation on test methods too, it is useful coupled with other annotations (it's the transactional coming from spring, not from jakarta, it's adding a different behavior):

* **@Commit**: by default, the data written on DB after an integration test annotated with @Transactional is deleted, this annotation avoids the delete.
* **@Rollback**: it ensures that the data written by the test is deleted after. (it is useless)

if you use both commit and rollback the result is unpredictable (it's stupid)
Another useful annotation is **@BeforeTransaction** which applied at method level ensures that the method is executed before all the @transactional annotated method of the test class.

In case multiple nested transactional annotated methods on the same object: only the exterior one will be wrapped by the proxy and create a single transaction in which all executes.
In order to have nested transactions, the nested trasactional method must be coming from a different object (which have a differnt proxy -> thus creating multiple wrapper around the methods)

**HIBERNATE**
JPA (java persistance API) is an API for persistance provider to implement, it offers useful annotation to be placed in DAO classes to define how the fields maps to the related tables in DB.
One of the JPA implementations is Hibernate.
Hibernate framework contains also Hibernate ORM, which is an ojbect relational mapping framework, advantages of having it:

* automatic mapping of objects (no need to write rowMapper code)
* provides HQL which is easier to read than SQL
* removes the need of ripetitive SQL code, thanks to method such as find, save.
* You can easily navigate between object to understand relationships of the tables
* it provides concurrency support
* it provides caching, _per transaction_ and _per datasource_
* it provides transaction management and isolation (HibernateTransactionManager bean)

Steps needed to configure directly (without JPA) Hibernate in a spring application:

* declare a dataSource bean as done before (it should support connection pooling though, more on this later)
* create a session factory bean, it is the core of hibernate, a thread-safe, immutable, shareable object that manages sessions (a session is a stateful object that manages persistent objects, it act as a cache, it is the main runtime interface between java and hibernate).

```
@Bean
public SessionFactory sessionFactory() {
    return new LocalSessionFactoryBuilder(dataSource())
        .scanPackages("com.example.dao")  //the packages where the classes to be mapped to DB tables are defined
        .addProperties(hibernateProperties())
        .buildSessionFactory();
}
```

* set the hibernateProperties (i'm using a bean here but it's not needed):

```
@Bean
public Properties hibernateProperties() {
    Priperties p = new Properties();
    p.put("hibernate.dialect", dialect);  //the sql dialect that is used in the DB
    p.put("hibernate.hbm2ddl.auto", hbm2ddl);  //this represents what hibernate should do when the application starts: none (the default - use this in prod), create-only, drop, create, create-drop, update, validate
    //for exmaple: create-drop: hibernate scan the entity and their relationship and it creates all the tables necessary when the application starts, and destroys all the tables when it turns off (useful for test)
    p.put("hibernate.show_sql", true); // logs the generated statements
    p.put("hibernate.use_sql_comments", true); // add comments over the logged sql statements
    p.put("hibernate.format_sql", true); //format the logged dql statements (prettifier)
    return p;
}
```

* if needed: declare the proper transaction manager:

```
@Bean
public PlatformTransactionManager() {
    return new HibernateTransactionManager(sessionFactory());
}
```

* in the repositories you can inject the sessionFactory, and then call the DB methods over the session obtained by: _sessionFactory.getCurrentSession();_

**Connection Pooling**: a way of reducing the computational cost of connecting to DB by using a pool of maintained connections, and perform diffferent operations in the pool.
In order to add connection  pooling you need to modify the dataSource configuration, here is an example using the HIKARI library which is the fastest connection pool in the java universe:
```
@Bean
public DataSource dataSource() {
    try {
        HikariConfig hc = new HikariConfig();
        hc.setDriverClassName(driverClassName);
        hc.setJdbcUrl(url);
        hc.setUsername(username);
        hc.setPassword(password);

        hc.setMaximumPoolSize(5);
        hc.setConnectionTestQuery("SELECT 1");
        hc.setPoolName("name");
        return new HikariDataSource(hc);
    } catch (Excpetion e) {
        //exception handling
    }
}
```

Hibernate is automatically mapping the DB results to classes using the JPA annotation with which they are  enriched. Hibernate can also execute explicit queries using Hibernate Query Language (HQL), example:
```
Person person = (Person) sessionFactory.getCurrentSession().createQuery("from Person p where p.username= :un").setParameter("un", username).uniqueResult();
```
You can also specify SQL native queries:
```
List<Person> persons = sessionFactory.getCurrentSession().createNativeQuery("select * from Person").getResultList();
```

while the default methods to contect the DB from the 'session' object are:

* update(entity)   //persist changes of an existing object in DB
* persist(entity)  //add a new row
* save(entity) //creates a new identifier for the obj and creates a new row in DB, returns also the generated id
* saveOrUpdate(entity)  // if the object exist -> update, otherwise save

Hibernate provides its own unchecked exceptions, but they will be mapped automatically to the springframework exceptions if the HibernateTransactionManager bean is configured.

**JPA Annotations**
HIbernate supports all the JPA annotations, the most useful are:

* **@Entity**: marks the class as a DAO, a domain object , to be mapped to a table (mandatory)
* **@Id**, marks the attribute of the class that will be the priary key of the table. (mandatory, at least one)
* **@GeneratedValue(strategy = [GenerationType.AUTO](http://GenerationType.AUTO))** : used to autogenerate a field value, useful for the primary key.
* **@MappedSuperclass**: when you have the need of grouping shared fields in an abstract class that is not mapped to a DB table but the class that extends it will be mapped.
* **@Version**: used to annotate the version field (needed to ensure integrity during complex operations in distributed environments)

it's using an optimistic lock on the DB. Spring is going to increment automatically the version, in case of two transactions updating the same field at the same time, at the commit time spring verifies that the version is updated in the meantime, if it has -> it throws OptimisticLockException.

* **@NotNull**: the field cannot be null
* **@Coulmn( name = "differentName", nullable = false, unique = true)**: specifies add initial behavior or the name of the DB column if different from the attribute name.
* **@Enumerated(EnumType.STRING)**: used for fields that are enums and that needs to be converted to string in  the DB.
* **@DateTimeFormat(pattern = "yyy-MM-dd")**: formats the LocalDate of java 8 to a string and viec-versa.
* **@Transient**: marks the field as not necessary to be persisted.
* **@OneToMany, @ManyToOne, @ManyToMany, @OneToOne**: they define the database relationships definitions, ex:

```
@Entity
public class Detective {
    @NotNull
    @OneToOne                            // the detective object has a one to one relationship with a person, the foreign key used in the relationship is: PERSON_ID
    @JoinColumn(name = "PERSON_ID")
    private Person person;

    @OneToMany(mappedBy = "detective")    // a detective is linked with multiples TrackEntry (name of the entity class representing another table), the mapping is done using the 'detective' column in the other table
    private Set<TrackEntry> trackEntries;

    @ManyToMany
    @JoinTable(                          // defines the extra table needed to perform the NxN relationship
        name="detective_to_case",        // name of the linking table
        joinColumns = @JoinColumn(name = "detective_id", referencedColumnName = "id"),  // the name to give to the ids in case of a join (avoid the clash of having the same name 'id' in both the entities)
        inverseJoinColumn = @JoinColumn(name = "case_id", referencedColumnName = "id")  // same as before but for an inverseJoin
    )
    private Set<CriminalCase> criminalCases;
}

@Entity
public class TrackEntry {
    @NotNull
    @ManyToOne
    @JoinColumn(name = "detective_fk")    // the name of the foreign key in the trackEntry table, which is used to link to the detective row.
    private Detective detective;    // the other side the 1toN relationship coming from the detective entity, from a 1toN there is a Nto1 declared somewhere else
}
```

**JPA**
If you run JPA without any infrastructure implementing it , you are running it in stand-alone : JSE. while in general you have an entire infrastructure JEE around.
In JEE you have to implement the entityMnager yourself making sure that it will be threadSave (one entity manager per thread).
JPA uses a file called MTEA-INF/persistance.xml which defines the persistanceUnit (it's like the configuration of the datasource), from which we will connect to the DB.

In spring you don't need any XML file.
it's the common interface for ORM and persistence, it operates over POJO classes tagged as entity. JPA has a **persistence context** containing a set of entities. it also has an **Entity manager** (it manages entities using create, update, querying and deletion), the entity manager is created by an **Entity Manager Factory**. it has **Persistence Unit** which is a group of entities managed by a single entity manager (multiple persistence units maps to multiple DBs in general).

How to add JPA (with hibernate implementation) in spring application:

* declare a _dataSource_ bean as done before
* declare a bean of type _LocalContainerEntityManagerFactoryBean_ (it's the entity manager factory):

```
@Bean
public EntityManagerFactory entityManagerFactory() {
    LocalContainerEntityManagerFactoryBean factoryBean = new LocalContainerEntityManagerFactoryBean();
    factoryBean.setPackagesToScan("com.example.dao");
    factoryBean.setDataSource(dataSource());
    factoryBean.setJpaVendorAdapter(new HibernateJpaVendorAdapter());
    factoryBean.setJpaProperties(hibernateProperties());  // this is the same as the one in the hibernate case
    factoryBean.afterPropertiesSet();
    return factoryBean.getNativeEntityManagerFactory();
}
```

* declare the transaction manager bean:

```
@Bean
public PlatformTransactionManager transactionManager() {
    return new JpaTransactionManager(entityManagerFactory())
}
```

* in the repository you can inject the _entityManager_ and perform DB operations with it:

```
@PersistenceContext    // this is the same as Autowired, but for the entity manager
EntityManager entityManager;
```

Methods exposed by the entityManager:

* find. example: _find(Person.class, personId);_
* createQuery   query written in JPQL - almost same as HQL (use_.getResultList()_ or _.getSingleResult()_ after this method)
* createNamedQuery, example: createNamedQuery("from Person p where p.firstName = :fn").setParameter("fn", "Mario").getSingleResult();
* createNativeQuery
* persist
* merge (doing an update on the row)
* flush, forces to write all the cached changes to the DB (not clean practice)
* refresh, forces a refresh of the cache for an entity
* remove, delete a row in DB

**SPRING DATA JPA**
Spring data is a spring project that works on top of JPA and following its standard, it simplyfies the developer's live by automating the repository implementation.
In order to use spring data you must enable it in the configuration:
```
@EnableJpaRepositories(
basePackage = "com.exmaple.dao"
transactionManagerRef = "jpaTransactionManager",  // the id of the bean JpaTransactionManager  (transactionManager by default)
entityManagerFactoryRef = "entiryManagerFactoryBean"  //the id of the bean exposing the EntityManagerFactory  (entiryManagerFactory by default)
)
```
you also need all the beans listed above for the JPA config.

You can use your repository interfaces as extensions of the _JpaRepository_ interface (which extends _PagingAndSortingRepository_, which in turn extends _CrudRepository_ which extends _Repository_). In this way the repositories will already implement the necessary method, plus if you need custom logic on top you can always define your own default method, or aternatively define his implememntation implicitly thorugh the _@Query_ annotation.
```
@Query("select p from Person p where p.username like %:username%")
Optional<Person> findByUsername(@Param("username") String username);
```

When you need to group some functionalities around a single class and then extend it with proper repositories, you may need a _BaseRepository_ extending _JpaRepository_ but this _BaseRepository_ doesn't need to be considered a @_Repository_ by spring (only the children do), so you can tag it with:
```
@NoRepositoryBean
```

**SPRING BOOT JPA**

With spring boot you don't even need a configuration to work with repositories that are implementing _JpaRepository_, it's enough to:

* include the dependency spring-boot-starter-jpa
* add the necessary info in the [application.properties](http://application.properties) / application.yml

```
spring:
    datasource:
        driver-class-name: org.h2.driver
        url: jdbc:h2:mem:db
        username: sa
        password: admin

//otherwise if you want to use also hikari connection ppol (already included in the dependencies under spring boot starter jpa)
spring:
    datasource:
        hikari:
            driver-class-name: org.h2.driver
            url: jdbc:h2:mem:db
            username: sa
            password: admin
            maximum-pool-size: 5
            connection-test-query: "SELECT 1"
            pool-name: mypool
```

to test the repository level using spring data JPA you can use @DataJpaTest instead of loading the whole context with @SpringBootTest.
DataJpaTest is creating a default database without considering your properties, and it destroys it after the tests.
